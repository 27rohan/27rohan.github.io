<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" />
<title>Data analytics, Machine Learning and Econometrics by Rohan Thakkar</title>
</head>

<body>
    <div id="page">
		
        <div id="header">
        	<div id="headerTitle">Rohan Manoj Thakkar</div>
            <div id="headerSubText">Graduate Student in Information Management (Data Science and Analytics)</div>
            <div id="headerSubText">The Information School - University of Washington, Seattle</div>
                    </div>
        <div id="bar">
       	    <a href="mailto:rohan27@uw.edu">Email</a> 
            <a href="https://www.linkedin.com/in/rohanmthakkar", target="_blank">LinkedIn</a>
<a href="https://github.com/27rohan", target="_blank">Github</a>
      </div>


<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/Web_scraping", target="_blank">Scraping course-catalog data from IIT Kharagpur's website</a></h1>
</div>
        <div class="contentText">

<a class="images" href="http://27rohan.github.io/Web_scraping", target="_blank">
<img src="iitk.jpg" alt="IIT-Kharagpur" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
<p>As a part of this project, I performed web scraping on the course-catalog data collected from the <a href="http://cse.iitkgp.ac.in/oldlook/curriculum.html", target="_blank"><i><u>Computer Science and Engineering</u></i></a>


 department of <b>Indian Institute of Technology - Kharagpur</b>.</p>
<p>&nbsp;</p>
<p>This was achieved in the iPython notebook environment using the Beautiful Soup web scraper and the resultant data-frame was pushed to a resultant CSV file, which was then hosted on AWS before being converetd into a MySQL database on an EC2 instance of AWS.</p>
<p>&nbsp;</p>
<p>The code can be viewed - <a href="http://27rohan.github.io/Web_scraping", target="_blank"><u>here</u></a>.  Also, I have included a visualization right there which will help understand how the frequency of courses falling within number of prerequisites varies.</p>

</div>


<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/Rotten-Tomatoes/", target="_blank">Implementing Naive Bayes classifier and PCA</a></h1>
</div>
        <div class="contentText">

<a class="images" href="http://27rohan.github.io/Rotten-Tomatoes/", target="_blank">
<img src="rotten.jpg" alt="Rotten tomatoes" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
<p>In this assignment, I'll be analyzing movie reviews in an attempt to determine whether movies are good or bad. I've downloaded a large number of movie reviews from the Rotten Tomatoes website. Also fetched is a file "movies.dat" that contains metadata for ~65,000 different movies. Using Python and commonly used machine learning algorithms from sckit-learn package, The mission is to develop a classifier to determine whether a movie is Fresh or Rotten based on the contents of the reviews given to the movie. 
<p>&nbsp;</p>
<p>The second part of this project is to understand the correlation of predictor variables in the Boston data set used below and apply dimensionality reduction using PCA to enhance performance of prediction.
<p>&nbsp;</p>
<p>The output of the same can be viewed <a href="http://27rohan.github.io/Rotten-Tomatoes/", target="_blank"><u>here</u></a>

</div>


<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/Boston/", target="_blank">Implementing commonly used machine learning algorithms on Boston dataset</a></h1>
</div>
        <div class="contentText">

<a class="images" href="http://27rohan.github.io/Boston/", target="_blank">
<img src="boston.jpg" alt="Progresa" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
	  <p> For this project, I used data from the <a href="http://archive.ics.uci.edu/ml/datasets/Housing", target="_blank"><u><b>UCI Archives</b></u></a>, which collected the dataset from the StatLib library which is maintained at Carnegie Mellon University.
 <p>&nbsp;</p>
<p>The goal of this analysis is to actually implement some of the basic machine learning algorithms to measure the impact of several predictor variables on the mean price of houses in Boston.</p>
        <p>&nbsp;</p>

<p> Using Python for machine learning, I evaluated the impact of 13 factors on the mean value of a house at Boston and the output of the same can be viewed <a href="http://27rohan.github.io/Boston/", target="_blank"><u>here</u></a>
</div>


<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/Progresa/", target="_blank">Evaluating the impact of Progresa</a></h1>
</div>
        <div class="contentText">

<a class="images" href="http://27rohan.github.io/Progresa/", target="_blank">
<img src="progresa.jpg" alt="Progresa" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
	  <p> For this project, I used data from the <a href="https://en.wikipedia.org/wiki/Oportunidadesa", target="_blank"><u><b>Progresa program</b></u></a>, a government social assistance program in Mexico. This program, as well as the details of its impact, are described in the paper <a href ="http://www.sciencedirect.com/science/article/pii/S0304387803001858" , target="_blank"><u>"School subsidies for the poor: evaluating the Mexican Progresa poverty program"</u></a>, by Paul Shultz.
The goal of this analysis is to implement some of the basic econometric techniques to measure the impact of Progresa on secondary school enrollment rates.</p>
        <p>&nbsp;</p>
The timeline of the program was:
<ul><li>Baseline survey conducted in 1997</li>
<li>Intervention begins in 1998, "Wave 1" of data collected in 1998</li>
<li>"Wave 2 of data" collected in 1999</li>
<li>Evaluation ends in 2000, at which point the control villages were treated.</li></ul>
<p>&nbsp;</p>
<p> Using Python for data analysis, I evaluated the impact of the program on socio-economic outcomes of individuals in Mexico and the output of the same can be viewed <a href="http://27rohan.github.io/Progresa/", target="_blank"><u>here</u></a>
</div>

<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/US_states/", target="_blank">Statistical and exploratory data analysis from US states 2010 census data</a></h1>
</div>
        <div class="contentText">

<a class="images" href="http://27rohan.github.io/US_states/", target="_blank">
<img src="US states.gif" alt="US Map" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
	  <p><b>United States</b> - the world's super power with an open source of data of the 50 states.  We go back in time and observe few visualizations based on data collected in the 1970s.  One can read the documentation of the 'state' data set <a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/state.html", target="_blank"><u>here</u></a></p>
        <p>&nbsp;</p>
<p> I performed exploratory data analysis on this data using R Studio and the output of the same can be viewed <a href="http://27rohan.github.io/US_states/", target="_blank"><u>here</u></a>
</div>


<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/SF/", target="_blank">San Francisco Crime Classification</a></h1>
</div>

<div class="contentText">

<a class="images" href="http://27rohan.github.io/SF/", target="_blank">
      <img src="SF.png" alt="Criminal" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>


<p>As my attempt to predict the category of crimes that occurred in the city by the bay, the dataset retrieved from <a href="https://www.kaggle.com/c/sf-crime", target="_blank"><i><u>Kaggle</u></i></a> is a collection of all crimes committed in <b>San Francisco</b> during the period of 6 June, 2003 to 13 May, 2015.</p>
<p>&nbsp;</p>
<p> I performed exploratory data analysis on this data using R Studio and the output of the same can be viewed <a href="http://27rohan.github.io/SF/", target="_blank"><u>here</u></a>
</div>

  
<div class="contentTitle"><h1>
  <a href="http://27rohan.github.io/NYC_flights/", target="_blank">Data analysis of flights from NYC in 2013</a></h1>
</div>
        <div class="contentText">
<a class="images" href="http://27rohan.github.io/NYC_flights/", target="_blank">
     	  <img src="nyc.jpg" alt="New York airport" style="width:670px;height:228px;"></a>
 <p>&nbsp;</p>
	  <p><b>New York</b> - one of the busiest airports in the world has several incoming and outgoing flights all year round.  R has a built-in package 'nycflights13' which has all information about flights from NYC in 2013.  One can read the documentation of the 'nycflights13' package <a href="https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf", target="_blank"><u>here</u></a></p>
        <p>&nbsp;</p>
<p> I performed exploratory data analysis on this data using R Studio and the output of the same can be viewed <a href="http://27rohan.github.io/NYC_flights/", target="_blank"><u>here</u></a>
</div>

 <p>&nbsp;</p>
</div>
        </div>
        <div id="footer">More visualizations coming soon...</div>
</body>
</html>
